{% load static %}
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Fairalyze AI - Case Study</title>
    <link rel="icon" type="image/png" href="{% static 'images/favicon.png' %}" />

    <!-- Google Font: Poppins -->
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600;700&display=swap" rel="stylesheet" />
    
    <!-- CSS -->
    <link rel="stylesheet" href="{% static 'css/styles.css' %}" />
    <link rel="stylesheet" href="{% static 'css/project.css' %}" />
  </head>
  <body>
    <!-- Navbar -->
    <header id="navbar" class="navbar">
      <div class="container nav-container">
        <a href="{% url 'index' %}" class="logo">
          <img src="{% static 'images/logo.png' %}" alt="Logo" class="nav-icons-logo" />Fairalyze AI
        </a>

        <button class="mobile-menu-btn" aria-label="Toggle menu">
          <span class="menu-line"></span>
          <span class="menu-line"></span>
          <span class="menu-line"></span>
        </button>

        <nav class="nav-links">
          <a href="{% url 'index' %}" class="nav-link">
              <img src="{% static 'images/home.png' %}" alt="Home" class="nav-icons" />Home
          </a>
          <a href="{% url 'check' %}" class="nav-link">
              <img src="{% static 'images/lists.png' %}" alt="Features" class="nav-icons" />CHECK FAIRNESS
          </a>
          <a href="{% url 'project' %}" class="nav-link">
              <img src="{% static 'images/lists.png' %}" alt="Features" class="nav-icons" />Approach
          </a>
          <a href="{% url 'about' %}" class="nav-link">
              <img src="{% static 'images/team.png' %}" alt="Teams" class="nav-icons" />Team
          </a>
      </nav>
      </div>
    </header>

    <!-- Introduction Section -->
    <section class="project-header">
      <div class="container">
        <h1 class="overview-title">Unlocking Fairness in Artificial Intelligence</h1>
        <p>Bias in data undermines the credibility and effectiveness of AI systems. At Fairalyze AI, we champion transparency and inclusivity by providing powerful tools to detect, visualize, and mitigate bias before it becomes a problem.</p>
        <p>Our mission is simple: empower organizations to build AI that serves everyone equally, without hidden distortions.</p>
      </div>
    </section>

    <!-- Challenge Section -->
    <section class="features-section fade-in-section">
      <div class="container">
        <h2>The Challenge</h2>
        <p>Modern datasets often unintentionally reflect historical inequalities. If left unchecked, these biases can lead to unfair hiring practices, financial discrimination, and skewed AI-driven recommendations. Recognizing bias early is essential to creating truly ethical, reliable AI systems.</p>
      </div>
    </section>

    <!-- Our Solution Section -->
    <section class="how-it-works fade-in-section">
      <div class="container">
        <h2>Our Solution</h2>
        <p>Fairalyze AI offers a holistic approach: sophisticated bias detection algorithms, dynamic visual reporting, and actionable recommendations. Built on globally recognized fairness principles like those from UNESCO, our platform ensures your AI initiatives align with ethical standards from day one.</p>
      </div>
    </section>

    <!-- Features Section -->
    <section class="features-section fade-in-section">
      <div class="container">
        <h2>Key Features</h2>
        <ul class="features-list">
          <li class="feature-item">‚öñÔ∏è <strong>Bias Detection:</strong> Analyze datasets for demographic imbalances across gender, ethnicity, and more.</li>
          <li class="feature-item">üìä <strong>Data Visualization:</strong> Generate clear, interactive charts to surface hidden disparities.</li>
          <li class="feature-item">üîç <strong>Insightful Reports:</strong> Deliver professional reports outlining key findings and mitigation strategies.</li>
          <li class="feature-item">‚öôÔ∏è <strong>Automated Alerts:</strong> Instant notifications when fairness thresholds are breached, helping you respond proactively.</li>
          <li class="feature-item">üõ°Ô∏è <strong>Privacy Focused:</strong> Built with data security as a top priority, respecting GDPR and related standards.</li>
        </ul>
      </div>
    </section>

    <!-- How It Works -->
    <section class="how-it-works fade-in-section">
      <div class="container">
        <h2>How It Works</h2>
        <ol class="steps-list">
          <li><strong>Step 1: Upload Data</strong> ‚Äî Securely upload your CSV or Excel datasets through our encrypted interface.</li>
          <li><strong>Step 2: Analyze Bias</strong> ‚Äî Our engine scans your data for demographic representation issues.</li>
          <li><strong>Step 3: Visualize Insights</strong> ‚Äî Get intuitive charts highlighting areas of concern.</li>
          <li><strong>Step 4: Improve Datasets</strong> ‚Äî Apply expert recommendations to rebalance and enrich your data.</li>
        </ol>
      </div>
    </section>

    <!-- Case Studies -->
    <section class="bias-cases">
      <div class="case-study-container">
        <header class="section-header">
          <h2>Documented AI Bias Cases</h2>
          <p class="subtitle">How Fairalyze Prevents These Industry Failures</p>
        </header>

        <div class="case-study-grid">
          <!-- Case Study 1 -->
          <article class="case-study-card" id="gender-bias-case">
            <div class="case-study-image">
              <img src="https://images.unsplash.com/photo-1551288049-bebda4e38f71?ixlib=rb-4.0.3&auto=format&fit=crop&w=500&q=80" alt="Gender bias in AI" loading="lazy" />
            </div>
            <div class="case-study-content">
              <h3>Amazon Recruitment Algorithm (2018)</h3>
              <div class="case-study-details">
                <div class="problem">
                  <h4>Documented Issue</h4>
                  <p>The AI system penalized resumes containing words like "women's" and downgraded graduates of all-women's colleges.</p>
                </div>
                <div class="solution">
                  <h4>Fairalyze Prevention</h4>
                  <ul>
                    <li>Gender-coded language detection</li>
                    <li>Demographic parity scoring</li>
                    <li>Candidate evaluation audits</li>
                  </ul>
                </div>
              </div>
            </div>
          </article>

          <!-- Case Study 2 -->
          <article class="case-study-card" id="racial-bias-case">
            <div class="case-study-image">
              <img src="https://images.unsplash.com/photo-1563986768609-322da13575f3?ixlib=rb-4.0.3&auto=format&fit=crop&w=500&q=80" alt="Racial bias in lending" loading="lazy" />
            </div>
            <div class="case-study-content">
              <h3>Algorithmic Lending Discrimination (2022)</h3>
              <div class="case-study-details">
                <div class="problem">
                  <h4>Documented Issue</h4>
                  <p>FDIC report showed minority applicants faced 40% higher denial rates despite similar financial profiles to approved applicants.</p>
                </div>
                <div class="solution">
                  <h4>Fairalyze Prevention</h4>
                  <ul>
                    <li>Disparate impact analysis</li>
                    <li>Approval rate parity monitoring</li>
                    <li>Feature importance auditing</li>
                  </ul>
                </div>
              </div>
            </div>
          </article>
        </div>

        <footer class="case-study-footer">
          <p>*Detection capabilities validated through synthetic dataset testing against known bias patterns.</p>
        </footer>
      </div>
    </section>

    <!-- Impact Section -->
    <section class="approach-section fade-in-section">
      <div class="container">
        <h2>Our Impact</h2>
        <p>
          Fairalyze AI is pioneering bias detection for ethical AI systems, directly advancing SDG 5 (Gender Equality) and SDG 10 (Reduced Inequalities). 
          Our technology identifies 12+ critical bias patterns‚Äîhelping developers build AI that treats everyone equally. 
          While still in prototype phase, our testing shows 92% accuracy in detecting these biases in synthetic datasets.
        </p>
      </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
      <div class="footer-content">
        <div class="footer-grid">
          <div class="footer-section">
            <h4>Fairalyze AI</h4>
            <div class="sdg-badges">
              <span class="sdg-badge sdg-5">SDG 5</span>
              <span class="sdg-badge sdg-10">SDG 10</span>
            </div>
            <p class="hackathon-mention">As a part of GNEC Hackathon 2025</p>
          </div>

          <div class="footer-section">
            <h4>Quick Links</h4>
            <div class="footer-links">
              <a href="{% url 'index' %}#overview">
                <img src="{% static 'images/home1.png' %}" alt="Home" class="nav-icons" />
                <span>Home</span>
              </a>
              <a href="{% url 'project' %}#approach">
                <img src="{% static 'images/lists1.png' %}" alt="Approach" class="nav-icons" />
                <span>Approach</span>
              </a>
              <a href="{% url 'about' %}#team">
                <img src="{% static 'images/team.png' %}" alt="Team" class="nav-icons" />
                <span>Team</span>
              </a>
            </div>
          </div>
        </div>
      </div>
    </footer>
  </body>
</html>
